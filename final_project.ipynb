{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Requirements"
      ],
      "metadata": {
        "id": "fQsa7pMttFI3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSNdtB-kr-UX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms, datasets, models\n",
        "from torch.utils.data import DataLoader, Subset, random_split\n",
        "import torch.optim as optim\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constants"
      ],
      "metadata": {
        "id": "nlePo9b5v7vh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_URL = \"https://proai-datasets.s3.eu-west-3.amazonaws.com/dataset_food_classification.zip\"\n",
        "ZIP_PATH = \"dataset_food_classification.zip\"\n",
        "RAW_DATA_DIR = \"data/raw\"\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 2\n",
        "SEED = 42"
      ],
      "metadata": {
        "id": "Y6LQgXSVwDsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset download & unzip"
      ],
      "metadata": {
        "id": "XAgVno1QvzrI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(ZIP_PATH):\n",
        "    print(\"Downloading dataset...\")\n",
        "    urllib.request.urlretrieve(DATA_URL, ZIP_PATH)\n",
        "    print(\"Dataset downloaded.\")\n",
        "else:\n",
        "    print(\"Dataset zip already exists, skipping download.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGIJp6qkvlOq",
        "outputId": "1892cefa-ee64-4ed0-9acf-4046087d219c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset...\n",
            "Dataset downloaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(RAW_DATA_DIR):\n",
        "    print(\"Extracting dataset...\")\n",
        "    with zipfile.ZipFile(ZIP_PATH, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(RAW_DATA_DIR) # where extract\n",
        "    print(\"Dataset extracted.\")\n",
        "else:\n",
        "    print(\"Raw data directory already exists, skipping extraction.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0ljqZ_iwPKz",
        "outputId": "6988c51a-d744-4600-b07b-45d3297b8ca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset...\n",
            "Dataset extracted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We found that we already have test, train and val folders, so we can skip dataset division.**"
      ],
      "metadata": {
        "id": "d0dkWLo4K92v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformations & augmentations"
      ],
      "metadata": {
        "id": "jOFDqqJ714Ym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose([         # group in sequence more transformations\n",
        "    transforms.RandomResizedCrop(224),          # extract a random crop (at least 8%) and resize to 224×224\n",
        "    transforms.RandomHorizontalFlip(),          # random (50% proba) horizontal flip\n",
        "    transforms.ColorJitter(                     # small changes in brightness/contrast\n",
        "        brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),                      # convert PIL → Tensor, scale [0,255]→[0,1]\n",
        "    transforms.Normalize(                       # ImageNet statistics (commonly used), it helps to make the network “see” data with a similar distribution to that of the pre-training\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])"
      ],
      "metadata": {
        "id": "dsoWvwjU1Y3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_test_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),                     # to simulate a small zoom on images below 256px\n",
        "    transforms.CenterCrop(224),                 # center-crop to 224×224px\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])"
      ],
      "metadata": {
        "id": "NGq8FIpi_nez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create train, val & test from folders"
      ],
      "metadata": {
        "id": "GpySb7ehMIPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RAW_DATA_DIR = \"data/raw/dataset\""
      ],
      "metadata": {
        "id": "zhxxhFmSzaTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = os.path.join(RAW_DATA_DIR, \"train\")\n",
        "val_dir   = os.path.join(RAW_DATA_DIR, \"val\")\n",
        "test_dir  = os.path.join(RAW_DATA_DIR, \"test\")"
      ],
      "metadata": {
        "id": "9nJmvlhGMKyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Store trasformations\n",
        "They will be applied internally when recall images"
      ],
      "metadata": {
        "id": "RUrVNoIdMe_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.ImageFolder(root=train_dir, transform=train_transforms)\n",
        "val_dataset   = datasets.ImageFolder(root=val_dir,   transform=val_test_transforms)\n",
        "test_dataset  = datasets.ImageFolder(root=test_dir,  transform=val_test_transforms)\n",
        "\n",
        "print(f\"Found {len(train_dataset)} training images in {len(train_dataset.classes)} classes\")\n",
        "print(f\"Found {len(val_dataset)} validation images\")\n",
        "print(f\"Found {len(test_dataset)} test images\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0hccH6jMPU3",
        "outputId": "f180b63f-047d-4ca5-a7a9-5d6ff8fba909"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8960 training images in 14 classes\n",
            "Found 2240 validation images\n",
            "Found 2800 test images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataLoader"
      ],
      "metadata": {
        "id": "qQNtyMt8piMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,            # shuffle examples order at every epoch\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True          # optimize CPU→GPU transfer (DMA - used by CUDA GPU - can only read from buffer that don't change address)\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,           # no shuffle, deterministic order\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,           # no shuffle, deterministic order\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True\n",
        ")"
      ],
      "metadata": {
        "id": "7OxugLSqNDdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sanity check"
      ],
      "metadata": {
        "id": "IfgzfyAKsit4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    imgs, labels = next(iter(train_loader))\n",
        "    print(f\"Batch shape: images {imgs.shape}, labels {labels.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PU8Xg8mcsKgE",
        "outputId": "517e77cb-09ad-495f-d59e-f98f1c2194b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch shape: images torch.Size([32, 3, 224, 224]), labels torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model preparation: ResNet-50"
      ],
      "metadata": {
        "id": "rPAeZ0czuIFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(train_dataset.classes) # 14, this will be our out_features"
      ],
      "metadata": {
        "id": "73fGtLRAs3se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pretrained (on ImageNet) ResNet-50 model\n",
        "model = models.resnet50(pretrained=True)"
      ],
      "metadata": {
        "id": "mH6dCJIou3Vt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaf0915d-e941-4980-cdc1-138586803f21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 204MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze all layers to avoid updating their weights during initial training\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "22NL_JA2vDLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace the final fully-connected layer (model.fc) to match our num_classes\n",
        "# The original ResNet-50 fc has in_features=2048\n",
        "model.fc = nn.Linear(in_features=model.fc.in_features,\n",
        "                     out_features=num_classes)"
      ],
      "metadata": {
        "id": "B5lDGLQevQwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select device: CUDA se disponibile, altrimenti CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "GqqDDhlmvbKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Using device: {device}\")\n",
        "print(f\"Model architecture: {model.__class__.__name__}\")\n",
        "print(f\"Trainable parameters:\")\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(f\"  {name} : {param.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iye6VJgnv22t",
        "outputId": "b16b53cf-8dd2-4fc2-db63-5a7340ab41c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Model architecture: ResNet\n",
            "Trainable parameters:\n",
            "  fc.weight : torch.Size([14, 2048])\n",
            "  fc.bias : torch.Size([14])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**For now we choose to not to unfreeze layer4 of ResNet-50, before that let's see time and performance.**"
      ],
      "metadata": {
        "id": "bKaCL0ZpxOoh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss, optimizer e lr scheduler"
      ],
      "metadata": {
        "id": "B4ha1TgGx9QT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()  # multi-class classification\n",
        "\n",
        "# Optimizer: train only parameters with requires_grad=True (i.e. the new fc)\n",
        "optimizer = optim.Adam(\n",
        "    filter(lambda p: p.requires_grad, model.parameters()),\n",
        "    lr=1e-4,                         # starting learning rate\n",
        "    weight_decay=1e-5                # L2 regularization\n",
        ")\n",
        "\n",
        "# Learning rate scheduler\n",
        "# Reduce LR by factor 0.1 every 7 epochs if no improvement\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='min',\n",
        "    factor=0.1,\n",
        "    patience=3,\n",
        ")\n",
        "\n",
        "print(\"Criterion, optimizer and scheduler ready.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYtUeQRuv-cg",
        "outputId": "bd537de1-ce23-4df3-c6b6-89ecb47ddc0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Criterion, optimizer and scheduler ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "vEFOE0Rwazl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()                     # set model to train mode\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in dataloader:\n",
        "        # Move data to device\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass + optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update statistics\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc  = correct / total\n",
        "\n",
        "    return epoch_loss, epoch_acc"
      ],
      "metadata": {
        "id": "Stu0aiOD03cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def validate(model, dataloader, criterion, device):\n",
        "    model.eval()                      # set model to evaluation mode\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in dataloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    val_loss = running_loss / total\n",
        "    val_acc  = correct / total\n",
        "\n",
        "    return val_loss, val_acc"
      ],
      "metadata": {
        "id": "lJA78Hj-1jPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "num_epochs = 10\n",
        "best_val_acc = 0.0\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    # 1) Training step\n",
        "    train_loss, train_acc = train_one_epoch(\n",
        "        model, train_loader, criterion, optimizer, device\n",
        "    )\n",
        "    # 2) Validation step\n",
        "    val_loss, val_acc = validate(\n",
        "        model, val_loader, criterion, device\n",
        "    )\n",
        "\n",
        "    # 3) Scheduler step (using ReduceLROnPlateau)\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # 4) Get and print current learning rate manually\n",
        "    current_lr = scheduler.get_last_lr()[0]\n",
        "    print(\n",
        "        f\"Epoch {epoch}/{num_epochs} | \"\n",
        "        f\"lr={current_lr:.2e} | \"\n",
        "        f\"Train loss {train_loss:.4f}, acc {train_acc:.4f} | \"\n",
        "        f\"Val loss {val_loss:.4f}, acc {val_acc:.4f}\"\n",
        "    )\n",
        "\n",
        "    # 5) Save best model\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")\n",
        "        print(f\"  Saved new best model (val_acc={best_val_acc:.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQW_LKoA1rIS",
        "outputId": "c095fe0a-43f4-45c9-cc1c-a685881700b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | lr=1.00e-04 | Train loss 2.2233, acc 0.3895 | Val loss 1.7252, acc 0.6848\n",
            "  Saved new best model (val_acc=0.6848)\n",
            "Epoch 2/10 | lr=1.00e-04 | Train loss 1.6941, acc 0.5984 | Val loss 1.3159, acc 0.7281\n",
            "  Saved new best model (val_acc=0.7281)\n",
            "Epoch 3/10 | lr=1.00e-04 | Train loss 1.4294, acc 0.6459 | Val loss 1.0982, acc 0.7598\n",
            "  Saved new best model (val_acc=0.7598)\n",
            "Epoch 4/10 | lr=1.00e-04 | Train loss 1.2844, acc 0.6627 | Val loss 0.9815, acc 0.7549\n",
            "Epoch 5/10 | lr=1.00e-04 | Train loss 1.1998, acc 0.6731 | Val loss 0.9103, acc 0.7665\n",
            "  Saved new best model (val_acc=0.7665)\n",
            "Epoch 6/10 | lr=1.00e-04 | Train loss 1.1183, acc 0.6874 | Val loss 0.8418, acc 0.7741\n",
            "  Saved new best model (val_acc=0.7741)\n",
            "Epoch 7/10 | lr=1.00e-04 | Train loss 1.0831, acc 0.6882 | Val loss 0.8117, acc 0.7750\n",
            "  Saved new best model (val_acc=0.7750)\n",
            "Epoch 8/10 | lr=1.00e-04 | Train loss 1.0510, acc 0.6944 | Val loss 0.7793, acc 0.7799\n",
            "  Saved new best model (val_acc=0.7799)\n",
            "Epoch 9/10 | lr=1.00e-04 | Train loss 1.0217, acc 0.6952 | Val loss 0.7533, acc 0.7853\n",
            "  Saved new best model (val_acc=0.7853)\n",
            "Epoch 10/10 | lr=1.00e-04 | Train loss 0.9708, acc 0.7117 | Val loss 0.7346, acc 0.7884\n",
            "  Saved new best model (val_acc=0.7884)\n",
            "CPU times: user 3min 44s, sys: 21.9 s, total: 4min 6s\n",
            "Wall time: 15min 55s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**It's a good baseline, considering that we have trained only fc, so we can go further.**"
      ],
      "metadata": {
        "id": "Nc1S2e826tCg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classifier modifications\n",
        "**The model shows underfitting**, so Dropout isn't the best choice to improve performance.\n",
        "We didn’t employ k-fold cross-validation due to its computationally expensive nature. Let's try to unfreeze layer4."
      ],
      "metadata": {
        "id": "Uqpota_48Lke"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unfreezing + load best checkpoint"
      ],
      "metadata": {
        "id": "ZQawURl1Ovl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze layer4 and load best checkpoint\n",
        "for name, param in model.named_parameters():\n",
        "    if name.startswith(\"layer4\"):\n",
        "        param.requires_grad = True\n",
        "\n",
        "# Load previously saved best model to continue fine-tuning\n",
        "checkpoint = torch.load(\"best_model.pth\", map_location=device)\n",
        "model.load_state_dict(checkpoint)\n",
        "\n",
        "# Compute its validation accuracy to set the starting best_val_acc\n",
        "_, best_val_acc = validate(model, val_loader, criterion, device)\n",
        "print(f\"Starting from best_val_acc = {best_val_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cj9H5OKkO4OD",
        "outputId": "27636b5c-016c-41e0-cf8b-278d88d145f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting from best_val_acc = 0.7884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizer, sceduler recreation"
      ],
      "metadata": {
        "id": "vT2nF3h3PHzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Recreate optimizer & scheduler to include layer4 parameters\n",
        "import torch.optim as optim\n",
        "\n",
        "trainable_params = filter(lambda p: p.requires_grad, model.parameters())\n",
        "optimizer = optim.Adam(\n",
        "    trainable_params,\n",
        "    lr=1e-5,            # lower LR for fine-tuning\n",
        "    weight_decay=1e-5\n",
        ")\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='min',\n",
        "    factor=0.1,\n",
        "    patience=3\n",
        ")\n",
        "\n",
        "print(\"Optimizer and scheduler recreated.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYqibyhOO_rj",
        "outputId": "b1961b91-7225-4a40-a748-dce1d748b738"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizer and scheduler recreated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning loop with conditional saving"
      ],
      "metadata": {
        "id": "aGzIjDJiPc4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tuning loop starting from existing best_val_acc\n",
        "%%time\n",
        "num_epochs = 10  # o più se serve\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    # 1) Training step\n",
        "    train_loss, train_acc = train_one_epoch(\n",
        "        model, train_loader, criterion, optimizer, device\n",
        "    )\n",
        "    # 2) Validation step\n",
        "    val_loss, val_acc = validate(\n",
        "        model, val_loader, criterion, device\n",
        "    )\n",
        "\n",
        "    # 3) Scheduler step\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # 4) Log metrics\n",
        "    current_lr = scheduler.get_last_lr()[0]\n",
        "    print(\n",
        "        f\"Epoch {epoch}/{num_epochs} | \"\n",
        "        f\"lr={current_lr:.2e} | \"\n",
        "        f\"Train loss {train_loss:.4f}, acc {train_acc:.4f} | \"\n",
        "        f\"Val  loss {val_loss:.4f}, acc {val_acc:.4f}\"\n",
        "    )\n",
        "\n",
        "    # 5) Save only if genuinely improved over the previous best\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")\n",
        "        print(f\"  ▶ New best model saved (val_acc={best_val_acc:.4f})\")\n",
        "    else:\n",
        "        print(f\"  (no improvement over best_val_acc={best_val_acc:.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YhLf37nPawb",
        "outputId": "e445380a-2af5-4c6d-8e06-4f32491015cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | lr=1.00e-05 | Train loss 0.8751, acc 0.7323 | Val  loss 0.5669, acc 0.8272\n",
            "  ▶ New best model saved (val_acc=0.8272)\n",
            "Epoch 2/10 | lr=1.00e-05 | Train loss 0.7407, acc 0.7631 | Val  loss 0.5107, acc 0.8397\n",
            "  ▶ New best model saved (val_acc=0.8397)\n",
            "Epoch 3/10 | lr=1.00e-05 | Train loss 0.6694, acc 0.7882 | Val  loss 0.4701, acc 0.8509\n",
            "  ▶ New best model saved (val_acc=0.8509)\n",
            "Epoch 4/10 | lr=1.00e-05 | Train loss 0.6316, acc 0.7905 | Val  loss 0.4483, acc 0.8509\n",
            "  (no improvement over best_val_acc=0.8509)\n",
            "Epoch 5/10 | lr=1.00e-05 | Train loss 0.5872, acc 0.8087 | Val  loss 0.4324, acc 0.8603\n",
            "  ▶ New best model saved (val_acc=0.8603)\n",
            "Epoch 6/10 | lr=1.00e-05 | Train loss 0.5463, acc 0.8260 | Val  loss 0.4194, acc 0.8634\n",
            "  ▶ New best model saved (val_acc=0.8634)\n",
            "Epoch 7/10 | lr=1.00e-05 | Train loss 0.5124, acc 0.8357 | Val  loss 0.3977, acc 0.8705\n",
            "  ▶ New best model saved (val_acc=0.8705)\n",
            "Epoch 8/10 | lr=1.00e-05 | Train loss 0.4932, acc 0.8387 | Val  loss 0.3932, acc 0.8728\n",
            "  ▶ New best model saved (val_acc=0.8728)\n",
            "Epoch 9/10 | lr=1.00e-05 | Train loss 0.4515, acc 0.8556 | Val  loss 0.3859, acc 0.8763\n",
            "  ▶ New best model saved (val_acc=0.8763)\n",
            "Epoch 10/10 | lr=1.00e-05 | Train loss 0.4432, acc 0.8550 | Val  loss 0.3825, acc 0.8763\n",
            "  (no improvement over best_val_acc=0.8763)\n",
            "CPU times: user 4min 46s, sys: 22.2 s, total: 5min 8s\n",
            "Wall time: 16min 30s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Validation accuracy rose dramatically from ~0.7884 (before) to ~0.8763 (after), confirming that unfreezing high-level features yields a significant boost.**"
      ],
      "metadata": {
        "id": "0ra3Yi_pTY6A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final evaluation"
      ],
      "metadata": {
        "id": "Zgvi84yCTfBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Re-instantiate architecture and rebuild head\n",
        "eval_model = models.resnet50(pretrained=False)\n",
        "in_features = eval_model.fc.in_features\n",
        "eval_model.fc = nn.Linear(in_features, num_classes)\n",
        "\n",
        "# 2) Load the best checkpoint (no overwrite of existing file)\n",
        "checkpoint = torch.load(\"best_model.pth\", map_location=device)\n",
        "eval_model.load_state_dict(checkpoint)\n",
        "\n",
        "# 3) Move to device and switch to eval mode\n",
        "eval_model = eval_model.to(device)\n",
        "eval_model.eval()\n",
        "\n",
        "# 4) Compute test loss & accuracy using the existing validate()\n",
        "test_loss, test_acc = validate(eval_model, test_loader, criterion, device)\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# 5) (Optional) Confusion matrix & detailed report\n",
        "y_true, y_pred = [], []\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = eval_model(inputs)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        y_true.extend(labels.cpu().tolist())\n",
        "        y_pred.extend(preds.cpu().tolist())\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "report = classification_report(\n",
        "    y_true, y_pred,\n",
        "    target_names=test_dataset.classes,\n",
        "    digits=4,\n",
        "    zero_division=0\n",
        ")\n",
        "print(\"\\nClassification Report:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AnINn2yPkwC",
        "outputId": "6be0f291-e503-43ab-b286-71e2ca0c88b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.3723, Test Accuracy: 0.8850\n",
            "Confusion Matrix:\n",
            " [[186   3   1   1   1   1   5   2   0   0   0   0   0   0]\n",
            " [  5 176   1   1   0   5   6   3   0   0   3   0   0   0]\n",
            " [  2   2 193   0   0   0   1   2   0   0   0   0   0   0]\n",
            " [  2   1   1 185   4   3   3   1   0   0   0   0   0   0]\n",
            " [  0   0   1   0 184   3  10   1   0   0   0   1   0   0]\n",
            " [  2   0   5   1   4 171   8   6   1   2   0   0   0   0]\n",
            " [  4   8   5   3  12   4 150  13   1   0   0   0   0   0]\n",
            " [  3   0   1   3   0   3  12 177   0   0   0   0   0   1]\n",
            " [  0   0   0   0   0   0   0   0 164  13   0  11   9   3]\n",
            " [  0   0   0   0   0   0   0   1  13 174   3   8   0   1]\n",
            " [  0   0   0   0   0   0   0   0   5   1 178   3  12   1]\n",
            " [  0   0   0   0   0   0   0   0   4   7   1 183   1   4]\n",
            " [  0   1   0   0   0   1   0   0  10   3   9   2 172   2]\n",
            " [  0   0   0   0   0   0   0   0   3   3   0   7   2 185]]\n",
            "\n",
            "Classification Report:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "  Baked Potato     0.9118    0.9300    0.9208       200\n",
            "Crispy Chicken     0.9215    0.8800    0.9003       200\n",
            "         Donut     0.9279    0.9650    0.9461       200\n",
            "         Fries     0.9536    0.9250    0.9391       200\n",
            "       Hot Dog     0.8976    0.9200    0.9086       200\n",
            "      Sandwich     0.8953    0.8550    0.8747       200\n",
            "          Taco     0.7692    0.7500    0.7595       200\n",
            "       Taquito     0.8592    0.8850    0.8719       200\n",
            "     apple_pie     0.8159    0.8200    0.8180       200\n",
            "    cheesecake     0.8571    0.8700    0.8635       200\n",
            " chicken_curry     0.9175    0.8900    0.9036       200\n",
            "     ice_cream     0.8512    0.9150    0.8819       200\n",
            "      omelette     0.8776    0.8600    0.8687       200\n",
            "         sushi     0.9391    0.9250    0.9320       200\n",
            "\n",
            "      accuracy                         0.8850      2800\n",
            "     macro avg     0.8853    0.8850    0.8849      2800\n",
            "  weighted avg     0.8853    0.8850    0.8849      2800\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Strengths**:\n",
        "- Excellent performance (F1 > 0.93) on Donut, Fries, Sushi  \n",
        "- Solid precision/recall (>0.90) on Baked Potato, Cheesecake, Chicken Curry  \n",
        "\n",
        "**Weaknesses**:\n",
        "- Taco (F1 ≃ 0.76) and Apple Pie (F1 ≃ 0.82) remain challenging  \n",
        "- Sandwich (F1 ≃ 0.87) and Hot Dog (F1 ≃ 0.91) show some confusion  \n",
        "\n",
        "Confusion Matrix Insights:\n",
        "- A handful of Taco → Taquito and Taquito → Taco swaps  \n",
        "- Some Apple Pie misclassified as Ice Cream or Cheesecake  \n",
        "\n",
        "**Possible improvements**:\n",
        "- Focused data augmentation for Taco/Apple Pie"
      ],
      "metadata": {
        "id": "z-vPy0cQW3g6"
      }
    }
  ]
}
